# CellDetector

The following code can be passed through the terminal:

## 0. Import Models and Packages

```tsx
pip install -r requirments.txt
```

If you wish to train a new model with our method, please see the following instructions (1: Training data preparation, 2:  Model training). If you wish to segment your own data directly with our trained model, please go to **3. Segmentation part**. 


## 1. Training data preparation (training folder)

### Ground truth generation

After getting ThunderSTORM results and the contour masks, you can use `groundtruth_generate.py` to generate the final ground truth.

- The input should be
    1. a csv file containing all possible cell locations generated by ThunderSTORM
    2. a folder of contour mask generated by image processing tools (ex. Amira3D, ImageJ, etc.)
- The output will be
    1. a folder with all mask images, which are the ground truth

Then, if you want to increase the intensity variation of the images, using `brightimg.py` to generate images with different gray level. The intensity variation parameter can be determined during code execution. 

- The input should be
    1. a folder with all mask images in it, which are the ground truth
- The output will be
    1. a folder with different gray level images

Next, use `dataset.py` to cut the images to fit the model input requirement and also augment data (optional), then all the training dataset will be generated.

- The input should be
    1. a folder with all mask images.
    2. a folder with raw images (including raw and modified intensity levels)
- The output will be
    1. a folder with final training dataset.

## 2. Model training

Using `unet.py` to train the U-net model

- The input should be
    1. a folder with final training dataset
- The output will be
    1. a trained model


## 3. Segmentation

Using `predict.py` to segment your raw data.

- The input should be
    1. a folder with raw images.
    2. trained model
- The output will be
    1. a folder with cell mask.

```tsx
python predict.py
```

![raw image](Untitled%20cf4e0f1eb3724caca8e894fb77ab065d/061490_084010_022500_ch1-2.jpg)

raw image

![mask](Untitled%20cf4e0f1eb3724caca8e894fb77ab065d/061490_084010_022500_ch1-1-1.jpg)

mask

![composite](Untitled%20cf4e0f1eb3724caca8e894fb77ab065d/Composite.jpg)

composite

## 4. Cell detection, registration, and intensity retrieval

This part of tools mainly modified from cellfinder. (Tyson, A. L., Rousseau, C. V., Niedworok, C. J., Keshavarzi, S., Tsitoura, C., Cossell, L., Strom, M. and Margrie, T. W. (2021) “A deep learning algorithm for 3D cell detection in whole mouse brain image datasets’ PLOS Computational Biology, 17(5), e1009074)

You can find more detailed instruction from https://github.com/brainglobe/cellfinder

In this part, we recommend to change another virtual environment, which should build in python>3.7.  Then, you can build the requirement in “cell_detection” folder.

```tsx
pip install -r requirments2.txt
```

Next, you can replace the file in [**cellfinder**](https://github.com/brainglobe/cellfinder)

- `main.py` in /envs/virtual_env_name/lib/site-packages\cellfinder\main.py
- `analyse.py` in envs/virtual_env_name/lib/site-packages\cellfinder\analyse\analyse.py
- The input should be
    1. a folder with mask images from model prediction as the mask channel.
    2. a folder with background images (for image registration) as the background channel.
    
    ( If you want to additionally extract the cell intensity in specific brain region, prepare the following inputs. )
    
    1. the brain regions to extract the cell intensity (whole brain will spend a long time)
    2. a folder with raw images of cell structures
- The output will be
    1. an output folder with the analysis result including a registered 3D brain annotation model, a cell location axis list, a cell density heatmap, a summary file list cell number in each brain region. If you add intensity retrieval function in previous section, another .csv file containing intensity level for each cell will be generated in analysis folder.

```tsx
cellfinder -s mask_channel -b background_channel -o output_folder -v 3.6 1.8 1.8 --orientation sal
```

## 5. Data analysis

- We use `ANOVA_analyze.py` to perform the ANOVA test across different experimental groups.
- We use [**brainrender**](https://github.com/brainglobe/brainrender) to visualize the significant brain region. `brain_region_visualization.py`
- random_forest
- correlation_matrix

## 6. Additional tools

- `rough_brain_region.py` : This is a tool to combine brain regions.
    - The input should be
        1. a csv file with targeted brain region level (1-6) including structure name and structure id path. (demo: “state_csv” folder)
        2. a csv file with cfos density. (demo: “cfos_group_csv” folder)
        3. a csv file with finest brain region level list.
    - The output will be
        1. an output folder with re-calculated cell density in targeted brain regions.
- `finer_region_replace.py`
-
